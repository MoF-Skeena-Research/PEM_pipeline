---
title: "03_run_models"
author: "W.H. MacKenzie"
date: "2023-03-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r setup}

devtools::load_all("D:\\GitHub\\PEMprepr")
devtools::load_all("D:\\GitHub\\PEMsamplr")
devtools::load_all("D:\\GitHub\\PEMmodelr")

library(PEMprepr)
library(PEMsamplr)
library(PEMmodelr)
library(dplyr)
library(sf)
require(tidymodels)
```

## Run models

```{r load data for model run}
# set up the standard inputs 
fid <- setup_folders("Deception_AOI")

in_dir <- fid$model_inputs0310[2]

fmat <- read.csv(file.path(in_dir, "fuzzy_matrix_basic_updated.csv" ))%>%
  dplyr::select(target, Pred, fVal)
# select reduced variables
reduced_vars <- read.csv(file.path(in_dir,  "reduced_covariate_list_dem_only.csv")) %>% dplyr::pull()

bgc_pts_subzone <- readRDS(file.path(fid$model_inputs0310[2], "model_input_pts.rds"))

```
### Optional tuning optimization step (takes a long time to run)

```{r hyperparameter tuning}
# trDat_centre <- as.data.frame(bgc_pts_subzone[[1]]) %>% filter(!mapunit1 == "") %>%
#  dplyr::filter(position %in% "Orig")
# 
# trDat <- trDat_centre %>%
#       mutate(slice = as.factor(slice))
# 
#         trDat <- trDat %>%
#           dplyr::select(mapunit1, slice, reduced_vars) %>%  drop_na() %>% mutate(target = factor(mapunit1)) %>%  droplevels()
# 
# # trDat <- trDat %>%
#         #   dplyr::select(-id, -position, -target2, -transect_id, -tid, -bgc_cat, -bgc) %>%  drop_na() %>% mutate(target = factor(target)) %>%  droplevels()
# 
# # downsample_ratio = 100
# # smote_ratio = .7
# bgc.label = unique(trDat$bgc_cat)
# 
# trees_split <- initial_split(trDat, strata = slice)
# trees_train <- training(trees_split)
# trees_test <- testing(trees_split)
# 
# tune_spec <- rand_forest(
#   mtry = tune(),
#   trees = 200,
#   min_n = tune()
# ) %>%
#   set_mode("classification") %>%
#   set_engine("ranger")
# 
#         best_recipe <-  recipe(target ~ ., data = trees_train) %>%
#           update_role(slice, new_role = "id variable")# %>%
#           #step_downsample(target, under_ratio = downsample_ratio) %>%
#           #step_smote(target, over_ratio = smote_ratio , neighbors = 10, skip = TRUE)
# tune_wf <- workflows::workflow() %>%
#   workflows::add_recipe(best_recipe) %>%
#   workflows::add_model(tune_spec)
# 
#  set.seed(234)
# trees_folds <- vfold_cv(trees_train)
# 
# doParallel::registerDoParallel()
# 
# set.seed(345)
# tune_res <- tune_grid(
#   tune_wf,
#   resamples = trees_folds,
#   grid = 10
# )
# 
# tune_res
# best_tune <- show_best(tune_res, metric = "roc_auc")
# best_tune2 <- show_best(tune_res, metric = "accuracy")
# 
# tune_res %>%
#   collect_metrics() %>%
#   filter(.metric == "roc_auc") %>%
#   dplyr::select(mean, min_n, mtry) %>%
#   pivot_longer(min_n:mtry,
#     values_to = "value",
#     names_to = "parameter"
#   ) %>%
#   ggplot(aes(value, mean, color = parameter)) +
#   geom_point(show.legend = FALSE) +
#   facet_wrap(~parameter, scales = "free_x") +
#   labs(x = NULL, y = "AUC")
# 
# best_tune <- select_best(tune_res, metric = "accuracy")
# 
# fwrite(best_tune, file.path (in_dir, "best_tuning_dem_only.csv"))

```
```{r select best tuning for a particular set of variables}
# set up tuning (applies to all models)
best_tune <- fread(file.path(in_dir, "best_tuning_dem_only.csv"))
mtry <- best_tune$mtry
min_n <- best_tune$min_n
```



## Run base model 

This runs the model with no balancing using the parameters generated in 02_prepare_model_inputs.R. 


```{r pressure, echo=FALSE}
xx=1
model_bgc <- lapply(names(bgc_pts_subzone), function(xx) {
  
  xx <- names(bgc_pts_subzone[xx])
  
  alldat = bgc_pts_subzone[[xx]]
  
  outDir = file.path(fid$model_draft[2], xx)
  
  dir.create(file.path(outDir, "raw_outputs"))
  detailed_outdir <- file.path(outDir, "raw_outputs")
 
  tdat <- alldat %>% mutate(slice = factor(slice))
  tdat <- tdat %>%
    dplyr::select(id, mapunit1, mapunit2, position,
      transect_id, tid, slice, any_of(reduced_vars))
  
  tdat <- tdat[complete.cases(tdat[, 8:length(tdat)]), ]
  
  train_data <- tdat 

  train_data <- droplevels(train_data)
  
  baseout <- run_base_model(
      train_data,
      fuzz_matrix = fmat,
      mtry = mtry,
      min_n = min_n,
      use.neighbours = TRUE, 
      detailed_output = FALSE, 
      out_dir = detailed_outdir)
  
  write.csv(baseout, file.path(detailed_outdir, "acc_base_results_dem.csv"))
  
  ## generate model accuracy report
  #model_report(train_data, baseout, outDir)
  
})

```


# Determine optimum Theta value for the metric of choice


<!-- ```{r} -->
<!-- bgcs <- list.dirs(fid$model_draft[2], recursive = T) -->

<!-- bgcs <- bgcs[endsWith(bgcs,"/raw_outputs")] -->

<!-- for(i in bgcs){ -->
<!--   i = bgcs[3] -->

<!--   out_dir <- gsub("/raw_outputs", "", i) -->

<!--   acc_out <- generate_theta_metrics(i) -->
<!--   write.csv(acc_out, file.path(out_dir, "compiled_theta_results.csv")) -->

<!--   theta_thresh <- generate_theta_threshold(acc_out) -->
<!--   write.csv(theta_thresh, file.path(out_dir, "theta_threshold.csv")) -->

<!-- #   overall_acc <- ggplot(aes(y = value, x = theta_final), data = acc_out ) +  -->
<!-- #     geom_boxplot() + -->
<!-- #     scale_fill_brewer(type = "qual") + -->
<!-- #     facet_wrap(~type, scales = "free_x")+ -->
<!-- #     geom_hline(yintercept = 0.65,linetype ="dashed", color = "black") +  -->
<!-- #     theme_pem_facet() + -->
<!-- #    # scale_fill_manual(values=c("grey90", "grey75", "grey50", "grey35","grey10"))+ -->
<!-- #     theme(axis.text.x = element_text(angle = 90, hjust = 1), legend.position="none") + -->
<!-- #     xlab("Metric") + ylab("Accuracy") +  -->
<!-- #     ylim(0, 1) -->
<!-- #  -->
<!-- # overall_acc -->

<!-- } -->

<!-- ``` -->

